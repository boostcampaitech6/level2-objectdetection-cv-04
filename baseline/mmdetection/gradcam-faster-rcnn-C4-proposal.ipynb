{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "from mmdet.datasets import replace_ImageToTensor\n",
    "from mmdet.datasets.pipelines import Compose\n",
    "from mmdet.datasets import (build_dataloader, build_dataset,\n",
    "                            replace_ImageToTensor)\n",
    "from mmdet.models import build_detector\n",
    "\n",
    "from mmcv.parallel import collate, scatter\n",
    "from mmcv.ops import RoIPool\n",
    "from mmcv import Config, DictAction\n",
    "from mmcv.runner import (get_dist_info, init_dist, load_checkpoint,\n",
    "                         wrap_fp16_model)\n",
    "from mmdet.core.utils import filter_scores_and_topk, select_single_mlvl\n",
    "from mmdet.core import (bbox2roi, multiclass_nms)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Init Your config and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = '../configs/Outliers/aster_rcnn_r50_fpn_1x_trash.py'\n",
    "config = './configs/Outliers/faster_rcnn_r50_fpn_1x_trash.py'\n",
    "cfg = Config.fromfile(config)\n",
    "\n",
    "# wget https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_caffe_c4_1x_coco/faster_rcnn_r50_caffe_c4_1x_coco_20220316_150152-3f885b85.pth\n",
    "checkpoint_path = './work_dirs/train_fold_5/latest.pth'\n",
    "device = 'cuda:0'\n",
    "model = init_detector(config)\n",
    "checkpoint = load_checkpoint(model, checkpoint_path, map_location=device)\n",
    "\n",
    "checkpoint['meta']['CLASSES']=('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass', \n",
    "           'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing')\n",
    "print(checkpoint['meta'].keys())\n",
    "# checkpoint.mets\n",
    "label_names = checkpoint['meta']['CLASSES']\n",
    "model.CLASSES = checkpoint['meta']['CLASSES']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"../../dataset/train/0005.jpg\"\n",
    "image = cv2.imread(image_path)\n",
    "# scale = 600 / min(image.shape[:2])\n",
    "# image = cv2.resize(image,\n",
    "#                    dsize = (448, 448),\n",
    "#                    interpolation=cv2.INTER_AREA)\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.imshow(image[:, :, ::-1])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the results with Faster R-CNN C4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = inference_detector(model, image)\n",
    "res = image.copy()\n",
    "for i, pred in enumerate(out):\n",
    "    for *box, score in pred:\n",
    "        if score < 0.4:\n",
    "            break\n",
    "        box = tuple(np.round(box).astype(int).tolist())\n",
    "        print(i, label_names[i], box, score)\n",
    "        cv2.rectangle(res, box[:2], box[2:], (0, 255, 0), 1)\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.imshow(res[:, :, ::-1])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. This is the core demo for Grad CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU version\n",
    "class GradCAM_FRCN(object):\n",
    "    \"\"\"\n",
    "    Grad CAM for Faster R-CNN C4 in mmdetection framework, this is not the latest, please refer to interpretation/gradcam.py\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, net, layer_name):\n",
    "        self.net = net\n",
    "        self.layer_name = layer_name\n",
    "        self.feature = None\n",
    "        self.gradient = None\n",
    "        self.net.eval()\n",
    "        self.handlers = []\n",
    "        self._register_hook()\n",
    "\n",
    "    def _get_features_hook(self, module, input, output):\n",
    "        self.feature = output\n",
    "        # print(\"feature shape:{}\".format(output.size()))\n",
    "\n",
    "    def _get_grads_hook(self, module, input_grad, output_grad):\n",
    "        \"\"\"\n",
    "        :param input_grad: tuple, input_grad[0]: None\n",
    "                                   input_grad[1]: weight\n",
    "                                   input_grad[2]: bias\n",
    "        :param output_grad:tuple\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.gradient = output_grad[0]\n",
    "\n",
    "    def _register_hook(self):\n",
    "        for (name, module) in self.net.named_modules():\n",
    "            if name == self.layer_name:\n",
    "                self.handlers.append(module.register_forward_hook(self._get_features_hook))\n",
    "                self.handlers.append(module.register_backward_hook(self._get_grads_hook))\n",
    "\n",
    "    def remove_handlers(self):\n",
    "        for handle in self.handlers:\n",
    "            handle.remove()\n",
    "    \n",
    "    def rpn_get_bboxes(self, cls_scores,\n",
    "                   bbox_preds,\n",
    "                   score_factors=None,\n",
    "                   img_metas=None,\n",
    "                   cfg=None,\n",
    "                   rescale=False,\n",
    "                   with_nms=False,\n",
    "                   **kwargs):\n",
    "        assert len(cls_scores) == len(bbox_preds)\n",
    "        if score_factors is None:\n",
    "            # e.g. Retina, FreeAnchor, Foveabox, etc.\n",
    "            with_score_factors = False\n",
    "        else:\n",
    "            # e.g. FCOS, PAA, ATSS, AutoAssign, etc.\n",
    "            with_score_factors = True\n",
    "            assert len(cls_scores) == len(score_factors)\n",
    "\n",
    "        num_levels = len(cls_scores)\n",
    "\n",
    "        featmap_sizes = [cls_scores[i].shape[-2:] for i in range(num_levels)]\n",
    "        mlvl_priors = self.net.rpn_head.prior_generator.grid_priors(\n",
    "            featmap_sizes,\n",
    "            dtype=cls_scores[0].dtype,\n",
    "            device=cls_scores[0].device)\n",
    "\n",
    "        result_list = []\n",
    "\n",
    "        for img_id in range(len(img_metas)):\n",
    "            img_meta = img_metas[img_id]\n",
    "            cls_score_list = select_single_mlvl(cls_scores, img_id, detach=False)\n",
    "            bbox_pred_list = select_single_mlvl(bbox_preds, img_id, detach=False)\n",
    "            if with_score_factors:\n",
    "                score_factor_list = select_single_mlvl(score_factors, img_id, detach=False)\n",
    "            else:\n",
    "                score_factor_list = [None for _ in range(num_levels)]\n",
    "\n",
    "            results = self.net.rpn_head._get_bboxes_single(cls_score_list, bbox_pred_list,\n",
    "                                              score_factor_list, mlvl_priors,\n",
    "                                              img_meta, cfg, rescale, with_nms,\n",
    "                                              **kwargs)\n",
    "            result_list.append(results)\n",
    "        return result_list\n",
    "    \n",
    "    def simple_test_bboxes(self,\n",
    "                           x,\n",
    "                           img_metas,\n",
    "                           proposals,\n",
    "                           rcnn_test_cfg,\n",
    "                           rescale=False):\n",
    "        \"\"\"Test only det bboxes without augmentation.\n",
    "        This function needn't read.\n",
    "        \"\"\"\n",
    "        rois = bbox2roi(proposals)\n",
    "        # print(\"rois: {}\".format(rois.shape))\n",
    "        if rois.shape[0] == 0:\n",
    "            batch_size = len(proposals)\n",
    "            det_bbox = rois.new_zeros(0, 5)\n",
    "            det_label = rois.new_zeros((0, ), dtype=torch.long)\n",
    "            if rcnn_test_cfg is None:\n",
    "                det_bbox = det_bbox[:, :4]\n",
    "                det_label = rois.new_zeros(\n",
    "                    (0, self.net.roi_head.bbox_head.fc_cls.out_features))\n",
    "            # There is no proposal in the whole batch\n",
    "            return [det_bbox] * batch_size, [det_label] * batch_size\n",
    "\n",
    "        bbox_results = self.net.roi_head._bbox_forward(x, rois)\n",
    "        img_shapes = tuple(meta['img_shape'] for meta in img_metas)\n",
    "        scale_factors = tuple(meta['scale_factor'] for meta in img_metas)\n",
    "\n",
    "        # split batch bbox prediction back to each image\n",
    "        cls_score = bbox_results['cls_score']\n",
    "        bbox_pred = bbox_results['bbox_pred']\n",
    "        num_proposals_per_img = tuple(len(p) for p in proposals)\n",
    "        rois = rois.split(num_proposals_per_img, 0)\n",
    "        cls_score = cls_score.split(num_proposals_per_img, 0)\n",
    "\n",
    "        # some detector with_reg is False, bbox_pred will be None\n",
    "        if bbox_pred is not None:\n",
    "            # TODO move this to a sabl_roi_head\n",
    "            # the bbox prediction of some detectors like SABL is not Tensor\n",
    "            if isinstance(bbox_pred, torch.Tensor):\n",
    "                bbox_pred = bbox_pred.split(num_proposals_per_img, 0)\n",
    "            else:\n",
    "                bbox_pred = self.net.roi_head.bbox_head.bbox_pred_split(\n",
    "                    bbox_pred, num_proposals_per_img)\n",
    "        else:\n",
    "            bbox_pred = (None, ) * len(proposals)\n",
    "\n",
    "        # apply bbox post-processing to each image individually\n",
    "        det_bboxes = []\n",
    "        det_labels = []\n",
    "        for i in range(len(proposals)):\n",
    "            if rois[i].shape[0] == 0:\n",
    "                # There is no proposal in the single image\n",
    "                det_bbox = rois[i].new_zeros(0, 5)\n",
    "                det_label = rois[i].new_zeros((0, ), dtype=torch.long)\n",
    "                if rcnn_test_cfg is None:\n",
    "                    det_bbox = det_bbox[:, :4]\n",
    "                    det_label = rois[i].new_zeros(\n",
    "                        (0, self.net.roi_head.bbox_head.fc_cls.out_features))\n",
    "\n",
    "            else:\n",
    "                det_bbox, det_label, det_inds = self.get_bboxes(\n",
    "                    rois[i],\n",
    "                    cls_score[i],\n",
    "                    bbox_pred[i],\n",
    "                    img_shapes[i],\n",
    "                    scale_factors[i],\n",
    "                    rescale=rescale,\n",
    "                    cfg=rcnn_test_cfg)\n",
    "            \n",
    "            det_bboxes.append(det_bbox)\n",
    "            det_labels.append(det_label)\n",
    "        return det_bboxes, det_labels, det_inds\n",
    "    \n",
    "    def get_bboxes(self,\n",
    "                   rois,\n",
    "                   cls_score,\n",
    "                   bbox_pred,\n",
    "                   img_shape,\n",
    "                   scale_factor,\n",
    "                   rescale=False,\n",
    "                   cfg=None):\n",
    "        \n",
    "        scores = F.softmax(\n",
    "            cls_score, dim=-1) if cls_score is not None else None\n",
    "        # bbox_pred would be None in some detector when with_reg is False,\n",
    "        # e.g. Grid R-CNN.\n",
    "        if bbox_pred is not None:\n",
    "            bboxes = self.net.roi_head.bbox_head.bbox_coder.decode(\n",
    "                rois[..., 1:], bbox_pred, max_shape=img_shape)\n",
    "        else:\n",
    "            bboxes = rois[:, 1:].clone()\n",
    "            if img_shape is not None:\n",
    "                bboxes[:, [0, 2]].clamp_(min=0, max=img_shape[1])\n",
    "                bboxes[:, [1, 3]].clamp_(min=0, max=img_shape[0])\n",
    "\n",
    "        if rescale and bboxes.size(0) > 0:\n",
    "            scale_factor = bboxes.new_tensor(scale_factor)\n",
    "            bboxes = (bboxes.view(bboxes.size(0), -1, 4) / scale_factor).view(\n",
    "                bboxes.size()[0], -1)\n",
    "        if cfg is None:\n",
    "            return bboxes, scores\n",
    "        else:\n",
    "            det_bboxes, det_labels, inds = multiclass_nms(bboxes, scores,     # return_inds=True\n",
    "                                                    cfg.score_thr, cfg.nms,\n",
    "                                                    cfg.max_per_img, return_inds=True)\n",
    "            return det_bboxes, det_labels, inds\n",
    "\n",
    "    def __call__(self, data, index=0):\n",
    "        \"\"\"\n",
    "        :param image: cv2 format, single image\n",
    "        :param index: Which bounding box\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.net.zero_grad()\n",
    "        # Important\n",
    "        feat = self.net.extract_feat(data['img'][0].cuda())\n",
    "\n",
    "        if type(data['img_metas'][0]) == list:\n",
    "            img_metas = data['img_metas'][0]\n",
    "        else:\n",
    "            img_metas = data['img_metas'][0].data[0]\n",
    "        \n",
    "        rpn_outs = self.net.rpn_head(feat)\n",
    "        proposal_list = self.rpn_get_bboxes(*rpn_outs, img_metas=img_metas)\n",
    "        # print(proposal_list[0].shape)\n",
    "        # proposal_list = model.rpn_head.simple_test_rpn(feat, img_metas)\n",
    "        # res = model.roi_head.simple_test(feat, proposal_list, img_metas, rescale=True)\n",
    "        res = self.simple_test_bboxes(feat, img_metas, proposal_list, self.net.roi_head.test_cfg, rescale=True)\n",
    "        ind = int(res[2][index]/len(self.net.CLASSES))\n",
    "        score = res[0][0][index][4]\n",
    "       \n",
    "        score.backward()\n",
    "        # print(res[0][0].shape)\n",
    "        # # print(self.gradient)\n",
    "        # print(self.feature.shape)\n",
    "        \n",
    "        gradient = self.gradient[ind]  # [C,H,W]\n",
    "        weight = torch.mean(gradient, axis=(1, 2))  # [C]\n",
    "\n",
    "        feature = self.feature[ind]  # [C,H,W]\n",
    "\n",
    "        cam = feature * weight[:, np.newaxis, np.newaxis]  # [C,H,W]\n",
    "        cam = torch.sum(cam, axis=0)  # [H,W]\n",
    "        cam = torch.relu(cam)  # ReLU\n",
    "\n",
    "        # Normalization\n",
    "        cam -= torch.min(cam)\n",
    "        cam /= torch.max(cam)\n",
    "        # resize to 224*224\n",
    "        box = res[0][0][index][:-1].cpu().detach().numpy().astype(np.int32)\n",
    "        \n",
    "        class_id = res[1][0][index].cpu().detach().numpy()\n",
    "        return cam.cpu().detach().numpy(), box, class_id, score.cpu().detach().numpy()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you just an image in opencv format, this is a preparation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_img(imgs):\n",
    "    if isinstance(imgs, (list, tuple)):\n",
    "        is_batch = True\n",
    "    else:\n",
    "        imgs = [imgs]\n",
    "        is_batch = False\n",
    "\n",
    "    cfg = model.cfg\n",
    "    device = next(model.parameters()).device  # model device\n",
    "\n",
    "    if isinstance(imgs[0], np.ndarray):\n",
    "        cfg = cfg.copy()\n",
    "        # set loading pipeline type\n",
    "        cfg.data.test.pipeline[0].type = 'LoadImageFromWebcam'\n",
    "\n",
    "    cfg.data.test.pipeline = replace_ImageToTensor(cfg.data.test.pipeline)\n",
    "    test_pipeline = Compose(cfg.data.test.pipeline)\n",
    "\n",
    "    datas = []\n",
    "    for img in imgs:\n",
    "        # prepare data\n",
    "        if isinstance(img, np.ndarray):\n",
    "            # directly add img\n",
    "            data = dict(img=img)\n",
    "        else:\n",
    "            # add information into dict\n",
    "            data = dict(img_info=dict(filename=img), img_prefix=None)\n",
    "        # build the data pipeline\n",
    "        data = test_pipeline(data)\n",
    "        datas.append(data)\n",
    "    # print(datas)\n",
    "\n",
    "    data = collate(datas, samples_per_gpu=len(imgs))\n",
    "    # just get the actual data from DataContainer\n",
    "    data['img_metas'] = [img_metas.data[0] for img_metas in data['img_metas']]\n",
    "    data['img'] = [img.data[0] for img in data['img']]\n",
    "    if next(model.parameters()).is_cuda:\n",
    "        # scatter to specified GPU\n",
    "        data = scatter(data, [device])[0]\n",
    "    else:\n",
    "        for m in model.modules():\n",
    "            assert not isinstance(\n",
    "                m, RoIPool\n",
    "            ), 'CPU inference with RoIPool is not supported currently.'\n",
    "\n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## These functions are used for rendering images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_image(image):\n",
    "    \"\"\"\n",
    "    :param image: [H,W,C]\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    image = image.copy()\n",
    "    image -= np.max(np.min(image), 0)\n",
    "    image /= np.max(image)\n",
    "    image *= 255.\n",
    "    return np.uint8(image)\n",
    "\n",
    "def gen_cam(image, mask):\n",
    "    \"\"\"\n",
    "    :param image: [H,W,C],\n",
    "    :param mask: [H,W], \n",
    "    :return: tuple(cam,heatmap)\n",
    "    \"\"\"\n",
    "    # mask to heatmap\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)\n",
    "    heatmap = np.float32(heatmap) / 255\n",
    "    heatmap = heatmap[..., ::-1]  # gbr to rgb\n",
    "\n",
    "    heatmap = cv2.resize(heatmap,\n",
    "        dsize = (image.shape[1], image.shape[0]))\n",
    "\n",
    "    # merge heatmap to original image\n",
    "    # cam = heatmap + np.float32(image)\n",
    "    return (heatmap * 255).astype(np.uint8)\n",
    "\n",
    "def plot_cam_image(img, mask, box, class_id, score, bbox_index, COLORS, label_names):\n",
    "    \"\"\"\n",
    "    Merge the CAM map to original image\n",
    "    \"\"\"\n",
    "    height, width = img.shape[:2]\n",
    "\n",
    "    image_tmp = img.copy()\n",
    "    x1, y1, x2, y2 = box\n",
    "    # predict_box = img[y1:y2, x1:x2]\n",
    "    image_heatmap = gen_cam(img[y1:y2, x1:x2], mask)\n",
    "    image_cam = img[y1:y2, x1:x2]*0.4+image_heatmap*0.6\n",
    "    \n",
    "    image_tmp[y1:y2, x1:x2] = image_cam\n",
    "\n",
    "    image_tmp = cv2.rectangle(image_tmp, (x1,y1), (x2,y2), COLORS[class_id], int(width/112))\n",
    "\n",
    "    label = label_names[class_id]\n",
    "    \n",
    "    cv2.putText(image_tmp, label+\": \"+\"%.2f\"%(score*100)+\"%\", (x1, y1-5), cv2.FONT_HERSHEY_DUPLEX,2, COLORS[class_id], 2)\n",
    "    \n",
    "    return image_tmp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For grad-cam, you need to choose a layer in the backbone, you can choose one from the name list below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, m in model.named_modules():\n",
    "    print(name,',',m) # roi_head.shared_head.layer4.2.conv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, you can choose 'roi_head.shared_head.layer4.2.conv3' or 'roi_head.shared_head.layer4.2' etc.\n",
    "grad_cam = GradCAM_FRCN(model, 'roi_head.bbox_roi_extractor')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(image_path)\n",
    "data = prepare_img(image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the mask through grad-cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First is the data, second is the index of the predicted bbox\n",
    "bbox_index = 0\n",
    "mask, box, class_id, score = grad_cam(data, bbox_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = np.random.uniform(0, 255, size=(len(label_names), 3))\n",
    "visual = plot_cam_image(image[:, :, ::-1], mask, box, class_id, score, bbox_index, COLORS, label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(visual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "data_path = '../../dataset/k-fold/val_fold_5.json'\n",
    "coco = COCO(data_path)\n",
    "image_infos = coco.loadImgs(coco.getImgIds())\n",
    "coco.getImgIds()\n",
    "img_pathes=[]\n",
    "for i in coco.getImgIds():\n",
    "    img_pathes.append(f\"../../dataset/train/{i:04d}.jpg\")\n",
    "\n",
    "img_pathes = enumerate(img_pathes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = next(img_pathes)[1]\n",
    "image = cv2.imread(img_path)\n",
    "out = inference_detector(model, image)\n",
    "res = image.copy()\n",
    "max_index=[]\n",
    "for i, pred in enumerate(out):\n",
    "    for *box, score in pred:\n",
    "        if score < 0.4:\n",
    "            break\n",
    "        box = tuple(np.round(box).astype(int).tolist())\n",
    "        print(i, label_names[i], box, score)\n",
    "        max_index.append(i)\n",
    "        cv2.rectangle(res, box[:2], box[2:], (0, 255, 0), 1)\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.imshow(image[:, :, ::-1])\n",
    "plt.show()\n",
    "print(max_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_cam = GradCAM_FRCN(model, 'roi_head.bbox_roi_extractor')\n",
    "image = cv2.imread(img_path)\n",
    "data = prepare_img(image)\n",
    "\n",
    "## First is the data, second is the index of the predicted bbox\n",
    "for idx, bbox_index in enumerate(max_index):\n",
    "    mask, box, class_id, score = grad_cam(data, idx)\n",
    "\n",
    "    COLORS = [[255,0,0],            # 빨강색 일쓰\n",
    "              [255,127.5,0],        # 주황색 종이\n",
    "              [255,255,0],          # 노랑색 종이팩\n",
    "              [0,255,0],            # 초록색 금속\n",
    "              [0,0,255],            # 파랑색 유리\n",
    "              [127.5,0,255],        # 보라색 플라스틱\n",
    "              [255,0,255],          # 마젠타 스티로폼\n",
    "              [0,255,255],          # 하늘색 비닐봉투\n",
    "              [255,127.5,127.5],    # 살색   빳데리\n",
    "              [127.5,127.5,127.5]]  # 회색   의류\n",
    "    visual = plot_cam_image(image[:, :, ::-1], mask, box, class_id, score, bbox_index, COLORS, label_names)\n",
    "    plt.imshow(visual)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmdet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b2312ad7d51b77951ea0c9de27fbcf9ed0e746d3dc268737bde9c3ba04c1ddd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
